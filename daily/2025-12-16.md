## AI洞察日报 2025/12/16

>  `AI 日报` 



### **今日摘要**

```
肯尼亚作者被AI误判引发争议
Tinker API开放并支持新模型
首个视频大语言模型可信度基准发布
AI取代劳动力税收归属成焦点
AI影响就业需设计过渡政策
```



### **今日AI资讯**

1.  **肯尼亚作者被AI写作质疑引发热议**：一位肯尼亚作者因其写作风格被误指为使用 ChatGPT，引发了关于写作风格判别、训练数据来源及社会偏见的广泛讨论。多位评论者指出，OpenAI 等公司在非洲聘请标注员参与 **RLHF**（Reinforcement Learning from Human Feedback）等任务，这或许解释了模型输出为何与某些地区的教育或商务英语风格相似。争论焦点还包括 **AI检测工具**的可靠性、以排版细节（如 **em dash**）作为判断依据的荒谬性，以及误判可能对作者、艺术社区和无障碍用户造成的伤害。

2.  **Thinking Machines Lab推出Tinker重大更新**：由前 OpenAI CTO Mira Murati 创办的 Thinking Machines Lab，其首款产品 **Tinker API**（用于简化 **LLM** 的后训练过程）现已取消候选名单，向所有用户开放。此次更新支持对 **Kimi K2 Thinking** 进行微调，该模型拥有万亿参数规模，专为长链推理和工具调用设计。此外，Tinker还新增了兼容 **OpenAI API** 的推理接口，并支持 **Qwen3-VL** 视觉模型，使其能够处理图片、截图等视觉内容，应用于监督微调和强化学习微调等多种场景。

3.  **AAAI 2026发布首个视频大语言模型可信度评测基准**：合肥工业大学与清华大学研究团队推出了 **Trust-videoLLMs**，这是首个针对视频大语言模型的综合可信度评测基准。该基准以 Oral 形式被 AAAI 2026 接收，全面评估了 5 款商业模型和 18 款开源模型的**真实性、鲁棒性、安全性、公平性**和**隐私性**。评测结果显示，闭源模型（如 Claude 和 Gemini 系列）普遍优于开源模型，但两者在某些维度上仍存在差距。研究发现，模型规模不直接等同于性能，视频上下文会显著放大模型的安全风险，且公平性问题普遍存在。

4.  **关于AI取代劳动力，税收归属成焦点**：针对AI可能取代劳动力的讨论，税收归属问题引发了广泛争论。一种观点认为AI是新型机器工具，不应直接征税，历史经验表明自动化会推动需求和新岗位产生。另一种观点则主张将税负放在**资本/财富**所有者身上，建议征收**财富税**、**资本利得税**，或对训练数据征收“版税”，并将收入用于 **UBI**（无条件基本收入）或公共项目。评论同时探讨了直接征税AI在**可执行性**和**逃逸风险**方面的困难，并提出了按**能源消耗（kWh）**或**计算量（tokens）**征税等替代方案。

5.  **AI对就业的影响与过渡政策的必要性**：关于AI是否会导致广泛、持久的失业，各方观点不一。一部分人引用**Jevons悖论**和工业化历史，认为自动化最终会吸收失业。另一部分人则指出，当前大型语言模型可能尚未达到一次性替代整套商业流程的程度，但短期冲击是真实的。多数评论认为，无论长期效果如何，都需要提前设计**过渡政策**，如 **WPA**（公共工程计划）式的措施、带资金来源的 **UBI** 或更积极的再分配措施，以应对自动化带来的社会转型挑战。

6.  **AI与税收的政治经济学考量**：大量评论将AI与税收问题的根本矛盾归结为政治经济力量。指出富豪与大公司通过税收漏洞大幅压低有效税率，导致税负向劳动转移并加剧社会不平等。有观点主张从严格**财富税**、强制估值与透明度，到限制个人财富上限等激进措施，以阻止财富进一步集中。尽管面临资本外流和政治阻力等风险，评论强调需要堵塞避税通道，并重建一个能将税基从劳动转向财富的制度。